# ğŸ“§ AnÃ¡lise de Dados e Machine Learning: ClassificaÃ§Ã£o de Emails

## ğŸ¯ Objetivo

Este documento demonstra o processo completo de anÃ¡lise de dados e construÃ§Ã£o de um modelo de machine learning para classificar emails como spam ou ham (legÃ­timo). Vamos aprender os conceitos fundamentais de processamento de texto, extraÃ§Ã£o de caracterÃ­sticas e classificaÃ§Ã£o usando Naive Bayes.

## ğŸ“š Conceitos que vamos aprender

- **Processamento de Texto**: Limpeza e preparaÃ§Ã£o de dados textuais
- **ExtraÃ§Ã£o de CaracterÃ­sticas**: ConversÃ£o de texto em nÃºmeros
- **ClassificaÃ§Ã£o**: Algoritmos para categorizar dados
- **Naive Bayes**: Modelo probabilÃ­stico para classificaÃ§Ã£o
- **ValidaÃ§Ã£o de Modelo**: VerificaÃ§Ã£o da qualidade das prediÃ§Ãµes

---

## ğŸ”§ ImportaÃ§Ã£o das Bibliotecas

Primeiro, vamos importar as bibliotecas necessÃ¡rias. Cada uma tem um papel especÃ­fico:

- **pandas**: ManipulaÃ§Ã£o e anÃ¡lise de dados
- **numpy**: ComputaÃ§Ã£o numÃ©rica
- **sklearn**: Algoritmos de machine learning
- **matplotlib/seaborn**: VisualizaÃ§Ã£o de dados
- **pickle**: SerializaÃ§Ã£o de modelos

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import pickle
```

---

## ğŸ“– Carregamento e ExploraÃ§Ã£o dos Dados

### O que Ã© Processamento de Texto?

Processamento de texto Ã© o conjunto de tÃ©cnicas para transformar dados textuais em formato que algoritmos de machine learning possam entender. Inclui:

- **Limpeza de texto**: RemoÃ§Ã£o de caracteres especiais, normalizaÃ§Ã£o
- **TokenizaÃ§Ã£o**: DivisÃ£o do texto em palavras
- **RemoÃ§Ã£o de stopwords**: Palavras muito comuns que nÃ£o agregam valor
- **LematizaÃ§Ã£o**: ReduÃ§Ã£o de palavras Ã  sua forma base

### Por que Ã© importante?

Texto bruto = Modelos ruins! O processamento adequado melhora significativamente a performance dos modelos de classificaÃ§Ã£o.

```python
# Carregando os dados do arquivo CSV
data = pd.read_csv('emails.csv', sep='|', header=0, names=['label', 'message'])

# Visualizando as primeiras linhas
print("Primeiras 5 linhas dos dados:")
print(data.head())

# InformaÃ§Ãµes sobre o dataset
print(f"\nDimensÃµes: {data.shape}")
print(f"Colunas: {list(data.columns)}")
print(f"\nDistribuiÃ§Ã£o das classes:")
print(data['label'].value_counts())
print(f"\nTipos de dados:")
print(data.dtypes)
```

---

## ğŸ”„ PrÃ©-processamento de Dados

### O que Ã© ExtraÃ§Ã£o de CaracterÃ­sticas?

ExtraÃ§Ã£o de caracterÃ­sticas Ã© o processo de converter texto em representaÃ§Ãµes numÃ©ricas que algoritmos de machine learning possam usar.

### TÃ©cnicas de ExtraÃ§Ã£o de CaracterÃ­sticas:

#### 1. **CountVectorizer** (Bag of Words)
- **Conceito**: Conta a frequÃªncia de cada palavra no texto
- **Vantagem**: Simples e eficaz
- **LimitaÃ§Ã£o**: NÃ£o considera ordem das palavras
- **Exemplo**: "Win free iPhone" â†’ [1, 1, 1, 0, 0, ...]

#### 2. **TF-IDF** (Term Frequency-Inverse Document Frequency)
- **Conceito**: Considera a importÃ¢ncia das palavras no corpus
- **Vantagem**: Reduz peso de palavras muito comuns
- **LimitaÃ§Ã£o**: Mais complexo computacionalmente

### Por que fazer isso?
- **Algoritmos numÃ©ricos**: Machine learning trabalha com nÃºmeros
- **PadronizaÃ§Ã£o**: Textos de diferentes tamanhos ficam comparÃ¡veis
- **ReduÃ§Ã£o de dimensionalidade**: Remove ruÃ­do e melhora performance

```python
# Preparando os dados
def prepare_data(data):
    """Prepara os dados para treinamento."""
    df = data.copy()
    df['label'] = df['label'].map({'spam': 1, 'ham': 0})
    return df

# Aplicando preparaÃ§Ã£o
df = prepare_data(data)

print("Dados preparados:")
print(f"Spam (1): {df['label'].value_counts()[1]} emails")
print(f"Ham (0): {df['label'].value_counts()[0]} emails")
print(f"\nExemplo de mensagem:")
print(df['message'].iloc[0])
```

---

## ğŸ” AnÃ¡lise ExploratÃ³ria dos Dados

### DistribuiÃ§Ã£o das Classes

Ã‰ importante verificar se os dados estÃ£o balanceados entre as classes:

```python
# Visualizando distribuiÃ§Ã£o das classes
plt.figure(figsize=(8, 6))
df['label'].value_counts().plot(kind='bar')
plt.title('DistribuiÃ§Ã£o de Classes')
plt.xlabel('Classe (0=Ham, 1=Spam)')
plt.ylabel('Quantidade')
plt.show()

print("DistribuiÃ§Ã£o das classes:")
print(df['label'].value_counts())
print(f"\nProporÃ§Ã£o:")
print(df['label'].value_counts(normalize=True))
```

### AnÃ¡lise de Palavras Frequentes

Vamos identificar as palavras mais comuns em spam vs ham:

```python
from collections import Counter
import re

def get_word_frequencies(texts, label):
    """Extrai frequÃªncia de palavras para uma classe."""
    all_words = []
    for text in texts:
        # Limpeza bÃ¡sica
        words = re.findall(r'\b\w+\b', text.lower())
        all_words.extend(words)
    
    return Counter(all_words)

# Palavras mais frequentes em spam
spam_texts = df[df['label'] == 1]['message']
spam_words = get_word_frequencies(spam_texts, 'spam')

# Palavras mais frequentes em ham
ham_texts = df[df['label'] == 0]['message']
ham_words = get_word_frequencies(ham_texts, 'ham')

print("Top 10 palavras em SPAM:")
for word, count in spam_words.most_common(10):
    print(f"{word}: {count}")

print("\nTop 10 palavras em HAM:")
for word, count in ham_words.most_common(10):
    print(f"{word}: {count}")
```

---

## ğŸ¤– ConstruÃ§Ã£o do Modelo de Machine Learning

### O que Ã© Naive Bayes?

Naive Bayes Ã© um algoritmo de classificaÃ§Ã£o baseado no teorema de Bayes. Ã‰ "naive" porque assume independÃªncia entre as caracterÃ­sticas.

### FÃ³rmula MatemÃ¡tica:
**P(Classe|CaracterÃ­sticas) âˆ P(CaracterÃ­sticas|Classe) Ã— P(Classe)**

Onde:
- **P(Classe|CaracterÃ­sticas)**: Probabilidade da classe dado as caracterÃ­sticas
- **P(CaracterÃ­sticas|Classe)**: Probabilidade das caracterÃ­sticas dado a classe
- **P(Classe)**: Probabilidade a priori da classe

### Por que Naive Bayes?
- **Simples e rÃ¡pido**: Computacionalmente eficiente
- **Bom baseline**: Funciona bem para classificaÃ§Ã£o de texto
- **Poucos dados**: Funciona mesmo com datasets pequenos
- **InterpretÃ¡vel**: FÃ¡cil de entender as prediÃ§Ãµes

```python
# Criando o pipeline de classificaÃ§Ã£o
from sklearn.pipeline import Pipeline

# CountVectorizer para extraÃ§Ã£o de caracterÃ­sticas
vectorizer = CountVectorizer(
    max_features=1000,  # Limita nÃºmero de caracterÃ­sticas
    stop_words='english',  # Remove stopwords
    ngram_range=(1, 2)  # Considera palavras e bigramas
)

# MultinomialNB para classificaÃ§Ã£o
classifier = MultinomialNB()

# Pipeline combinando vectorizer e classificador
pipeline = Pipeline([
    ('vectorizer', vectorizer),
    ('classifier', classifier)
])

print("Pipeline criado com sucesso!")
print("Etapas:")
print("1ï¸âƒ£  CountVectorizer: ExtraÃ§Ã£o de caracterÃ­sticas")
print("2ï¸âƒ£  MultinomialNB: ClassificaÃ§Ã£o")
```

---

## ğŸ“Š Treinamento e AvaliaÃ§Ã£o do Modelo

### DivisÃ£o dos Dados

Ã‰ crucial dividir os dados em treino e teste para avaliar a performance real do modelo:

```python
# Dividindo os dados
X = df['message']
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"DivisÃ£o dos dados:")
print(f"Treino: {X_train.shape[0]} emails")
print(f"Teste: {X_test.shape[0]} emails")
print(f"\nDistribuiÃ§Ã£o no treino:")
print(y_train.value_counts())
print(f"\nDistribuiÃ§Ã£o no teste:")
print(y_test.value_counts())
```

### Treinamento do Modelo

```python
# Treinando o modelo
pipeline.fit(X_train, y_train)

print("âœ… Modelo treinado com sucesso!")

# Fazendo prediÃ§Ãµes no conjunto de teste
y_pred = pipeline.predict(X_test)

print(f"\nPrediÃ§Ãµes realizadas: {len(y_pred)}")
print(f"Spam preditos: {sum(y_pred == 1)}")
print(f"Ham preditos: {sum(y_pred == 0)}")
```

### AvaliaÃ§Ã£o do Modelo

```python
# RelatÃ³rio de classificaÃ§Ã£o
print("ğŸ“Š RelatÃ³rio de ClassificaÃ§Ã£o:")
print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))

# Matriz de confusÃ£o
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Matriz de ConfusÃ£o')
plt.xlabel('Predito')
plt.ylabel('Real')
plt.show()

print("\nğŸ“ˆ MÃ©tricas de Performance:")
print(f"PrecisÃ£o: {cm[1,1] / (cm[1,1] + cm[0,1]):.3f}")
print(f"Recall: {cm[1,1] / (cm[1,1] + cm[1,0]):.3f}")
print(f"F1-Score: {2 * cm[1,1] / (2 * cm[1,1] + cm[0,1] + cm[1,0]):.3f}")
```

---

## ğŸ” AnÃ¡lise de Erros

### O que sÃ£o Falsos Positivos e Falsos Negativos?

- **Falso Positivo**: Email legÃ­timo classificado como spam
- **Falso Negativo**: Spam classificado como legÃ­timo

### Por que analisar erros?
- **Melhorar o modelo**: Identificar padrÃµes problemÃ¡ticos
- **Ajustar threshold**: Balancear precisÃ£o vs recall
- **Feature engineering**: Criar caracterÃ­sticas mais discriminativas

```python
# Identificando erros de classificaÃ§Ã£o
errors = X_test[y_test != y_pred]
error_labels = y_test[y_test != y_pred]
error_predictions = y_pred[y_test != y_pred]

print("ğŸ” AnÃ¡lise de Erros:")
print(f"Total de erros: {len(errors)}")

# Falsos positivos (ham classificado como spam)
fp_indices = (y_test == 0) & (y_pred == 1)
fp_count = sum(fp_indices)

# Falsos negativos (spam classificado como ham)
fn_indices = (y_test == 1) & (y_pred == 0)
fn_count = sum(fn_indices)

print(f"Falsos Positivos (Ham â†’ Spam): {fp_count}")
print(f"Falsos Negativos (Spam â†’ Ham): {fn_count}")

# Exemplos de erros
if len(errors) > 0:
    print(f"\nğŸ“ Exemplos de erros:")
    for i, (text, true_label, pred_label) in enumerate(zip(errors, error_labels, error_predictions)):
        if i < 3:  # Mostra apenas os primeiros 3
            label_names = {0: 'Ham', 1: 'Spam'}
            print(f"Texto: {text[:100]}...")
            print(f"Real: {label_names[true_label]}, Predito: {label_names[pred_label]}")
            print("-" * 50)
```

---

## ğŸš€ Modelo Final e PrediÃ§Ãµes

### Salvando o Modelo

```python
# Salvando o modelo treinado
with open('model.pkl', 'wb') as f:
    pickle.dump(pipeline, f)

print("ğŸ’¾ Modelo salvo com sucesso!")
```

### FunÃ§Ã£o de PrediÃ§Ã£o

```python
def predict_email(message):
    """
    Prediz se um email Ã© spam ou ham.
    
    Args:
        message (str): Texto do email
        
    Returns:
        str: 'spam' ou 'ham'
    """
    # Carregando o modelo
    with open('model.pkl', 'rb') as f:
        model = pickle.load(f)
    
    # Fazendo prediÃ§Ã£o
    prediction = model.predict([message])[0]
    
    return 'spam' if prediction == 1 else 'ham'

# Testando o modelo
test_messages = [
    "Win a free iPhone now! Click here!",
    "Hello, how are you? Let's meet tomorrow.",
    "URGENT: Your account has been suspended!",
    "Please review the attached document.",
    "Free money! Make $1000/day from home!"
]

print("ğŸ§ª Testando o Modelo:")
for message in test_messages:
    prediction = predict_email(message)
    print(f"'{message[:50]}...' â†’ {prediction}")
```

---

## ğŸ“Š AnÃ¡lise de Probabilidades

### Por que analisar probabilidades?

As probabilidades nos dÃ£o mais informaÃ§Ã£o sobre a confianÃ§a do modelo:

```python
def predict_with_probability(message):
    """
    Prediz com probabilidade de confianÃ§a.
    """
    with open('model.pkl', 'rb') as f:
        model = pickle.load(f)
    
    # Probabilidades para cada classe
    probabilities = model.predict_proba([message])[0]
    
    prediction = 'spam' if probabilities[1] > probabilities[0] else 'ham'
    confidence = max(probabilities)
    
    return prediction, confidence

# Testando com probabilidades
print("ğŸ“Š PrediÃ§Ãµes com Probabilidade:")
for message in test_messages:
    pred, conf = predict_with_probability(message)
    print(f"'{message[:40]}...' â†’ {pred} (confianÃ§a: {conf:.3f})")
```

---

## ğŸ“ Resumo do que Aprendemos

### ğŸ“Š **Processamento de Texto**
- **ImportÃ¢ncia**: Texto limpo = modelos melhores
- **TÃ©cnicas**: CountVectorizer, TF-IDF
- **Ferramentas**: NLTK, spaCy (para processamento avanÃ§ado)

### ğŸ¤– **Machine Learning**
- **Algoritmo**: Multinomial Naive Bayes
- **Objetivo**: Classificar emails como spam/ham
- **AplicaÃ§Ã£o**: Filtros de spam, moderaÃ§Ã£o de conteÃºdo

### ğŸ” **ValidaÃ§Ã£o de Modelo**
- **MÃ©tricas**: PrecisÃ£o, Recall, F1-Score
- **Matriz de confusÃ£o**: AnÃ¡lise de erros
- **Probabilidades**: ConfianÃ§a das prediÃ§Ãµes

### ğŸš€ **PrÃ³ximos Passos**
- Experimentar outros algoritmos (SVM, Random Forest)
- Feature engineering mais avanÃ§ado (word embeddings)
- ValidaÃ§Ã£o cruzada
- OtimizaÃ§Ã£o de hiperparÃ¢metros

### ğŸ’¡ **Conceitos-Chave**
1. **Texto Ã© diferente**: Precisa de processamento especial
2. **ExtraÃ§Ã£o de caracterÃ­sticas Ã© crucial**: Boas features = bom modelo
3. **Balanceamento importa**: Classes desbalanceadas afetam performance
4. **Interpretabilidade Ã© Ãºtil**: Entender por que o modelo classifica

---

**ğŸ¯ Lembre-se**: ClassificaÃ§Ã£o de texto Ã© uma Ã¡rea rica em possibilidades. Comece simples, valide sempre, melhore gradualmente!

---

## ğŸ“ CÃ³digo Completo

```python
# ImportaÃ§Ã£o das bibliotecas
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.pipeline import Pipeline
import pickle

# Carregamento dos dados
data = pd.read_csv('emails.csv', sep='|', header=0, names=['label', 'message'])

# PreparaÃ§Ã£o dos dados
data['label'] = data['label'].map({'spam': 1, 'ham': 0})

# DivisÃ£o dos dados
X = data['message']
y = data['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# CriaÃ§Ã£o do pipeline
vectorizer = CountVectorizer(max_features=1000, stop_words='english')
classifier = MultinomialNB()
pipeline = Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])

# Treinamento do modelo
pipeline.fit(X_train, y_train)

# AvaliaÃ§Ã£o
y_pred = pipeline.predict(X_test)
print(classification_report(y_test, y_pred))

# Salvando o modelo
with open('model.pkl', 'wb') as f:
    pickle.dump(pipeline, f)

# PrediÃ§Ã£o
def predict_email(message):
    with open('model.pkl', 'rb') as f:
        model = pickle.load(f)
    prediction = model.predict([message])[0]
    return 'spam' if prediction == 1 else 'ham'

# Teste
result = predict_email("Win a free iPhone now!")
print(f"PrediÃ§Ã£o: {result}")
``` 